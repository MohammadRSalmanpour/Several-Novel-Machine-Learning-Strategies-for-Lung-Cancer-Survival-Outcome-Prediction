{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uij0hs87KJ3c",
        "outputId": "d8dd2461-faaf-443b-f451-8196c31a0b77"
      },
      "outputs": [],
      "source": [
        "! pip install scikit-learn==1.1.3\n",
        "! pip install scikit-survival\n",
        "! pip install lifelines\n",
        "! pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guUmGZploOLD"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# @title Import libs\n",
        "import pandas as pd\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines.statistics import logrank_test\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import (GridSearchCV, cross_val_predict,cross_validate)\n",
        "from sksurv.ensemble import (ComponentwiseGradientBoostingSurvivalAnalysis,\n",
        "                             RandomSurvivalForest)\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "from sksurv.svm import FastSurvivalSVM\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be7zM_m1sSJL"
      },
      "outputs": [],
      "source": [
        "#@title Survival Algorithms & Params\n",
        "rsf_param_grid = param_grid = {'n_estimators': np.arange(1, 10),\n",
        "                          'min_samples_split': np.arange(6,10,1)\n",
        "                          }\n",
        "\n",
        "cwgb_param_grid = {\n",
        "              'loss': ['coxph' , 'squared' ],\n",
        "              'learning_rate': [1, 10, 100 ],\n",
        "              'dropout_rate': [0.1, 0.5, 0.9],\n",
        "              'n_estimators': [10],\n",
        "            }\n",
        "\n",
        "fsvm_param_grid = {'alpha': 2. ** np.arange(-10, 10, 5),\n",
        "                'optimizer': ['avltree' , 'direct-count' ,'PRSVM'  ,'rbtree'  , 'simple' ]\n",
        "              }\n",
        "# Define the regressors and their respective parameter spaces\n",
        "survival_algs = {\n",
        "    'RandomSurvivalForest':(RandomSurvivalForest(random_state=42),rsf_param_grid),\n",
        "    'ComponentwiseGradientBoostingSurvivalAnalysis' :(ComponentwiseGradientBoostingSurvivalAnalysis(random_state=42),cwgb_param_grid),\n",
        "    'FastSurvivalSVM': (FastSurvivalSVM(max_iter=512, tol=1e-6, random_state=42), fsvm_param_grid)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrVBg3-uly5T"
      },
      "outputs": [],
      "source": [
        "n_feats = [10]\n",
        "\n",
        "result_path = \"/\"\n",
        "feature_path = \"/\"\n",
        "\n",
        "def append_row(df, row):\n",
        "    return pd.concat([\n",
        "                df,\n",
        "                pd.DataFrame([row], columns=row.index)]\n",
        "          ).reset_index(drop=True)\n",
        "def score_survival_model(model, X, y):\n",
        "    prediction = model.predict(X)\n",
        "    result = concordance_index_censored(y['Event'], y['Duration'], prediction)\n",
        "    return result[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_czC5Vcbl-8a"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "files = glob.glob(feature_path +\"*\")\n",
        "datasets = []\n",
        "for filee in files:\n",
        "  datasets.append(filee.split(\"/\")[-1].split(\".\")[0])\n",
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaopegfhlfVS"
      },
      "outputs": [],
      "source": [
        "#@title Survival analysis\n",
        "\n",
        "runs_df = pd.DataFrame()\n",
        "\n",
        "n=0\n",
        "# Step 1: Prepare your data\n",
        "for dataset in datasets:\n",
        "  for name, (reg, param_space) in survival_algs.items():\n",
        "\n",
        "    n=n+1\n",
        "    path = feature_path+dataset+\".xlsx\"\n",
        "    Y = pd.read_csv(\"COX_OUTCOME.csv\",header=0)\n",
        "    X = pd.read_excel(path, sheet_name='Data' , engine='openpyxl',header=0).reindex()\n",
        "\n",
        "    Y = Y[['Event','Duration']]\n",
        "    Y['Event'] = Y['Event'].astype(bool)\n",
        "    Y['Duration'] = Y['Duration'].astype(float)/365\n",
        "\n",
        "    X.columns = X.columns.astype(str)\n",
        "    Y = Y.to_records(index=False)\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,random_state=101)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Create PCA instance: PCA for 5 components\n",
        "    pca = PCA(n_components=5)\n",
        "    X_train = pca.fit_transform(X_train)\n",
        "    X_test = pca.transform(X_test)\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=reg, param_grid=param_space, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Step 5: Retrieve the best model from grid search\n",
        "    best_regressor = grid_search.best_estimator_\n",
        "\n",
        "    # Step 6: Evaluate the best model using cross-validation\n",
        "    train_scores = cross_validate(best_regressor, X_train, y_train, cv=5, scoring=score_survival_model)\n",
        "    test_test_score = best_regressor.score(X_test, y_test)\n",
        "\n",
        "    test_risk_scores = cross_val_predict(best_regressor, X_test, y_test, cv=5)\n",
        "    train_risk_scores = cross_val_predict(best_regressor, X_train, y_train, cv=5)\n",
        "\n",
        "    train_threshold = np.percentile(train_risk_scores, 50)\n",
        "    test_threshold = np.percentile(test_risk_scores, 50)\n",
        "\n",
        "    test_high_risk = y_test[test_risk_scores >= test_threshold]\n",
        "    test_low_risk = y_test[test_risk_scores < test_threshold]\n",
        "\n",
        "    train_high_risk = y_train[train_risk_scores >= train_threshold]\n",
        "    train_low_risk = y_train[train_risk_scores < train_threshold]\n",
        "\n",
        "    if len(train_low_risk)>0 and len(train_high_risk)>0:\n",
        "\n",
        "      test_results = logrank_test( test_low_risk[\"Duration\"],  test_high_risk[\"Duration\"],\n",
        "                              event_observed_A=test_low_risk[\"Event\"], event_observed_B=test_high_risk[\"Event\"])\n",
        "\n",
        "      results = logrank_test( train_low_risk[\"Duration\"],  train_high_risk[\"Duration\"],\n",
        "                              event_observed_A=train_low_risk[\"Event\"], event_observed_B=train_high_risk[\"Event\"])\n",
        "\n",
        "      kmf = KaplanMeierFitter()\n",
        "      kmf2 = KaplanMeierFitter()\n",
        "      plt.clf()\n",
        "      kmf.fit(train_high_risk[\"Duration\"], train_high_risk[\"Event\"],label='High Risk')\n",
        "\n",
        "      kmf2.fit(train_low_risk[\"Duration\"], train_low_risk[\"Event\"],label='Low Risk')\n",
        "\n",
        "      ax = plt.subplot(111)\n",
        "\n",
        "      ax = kmf.plot(color='Gold', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "      ax = kmf2.plot(color='Teal', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "      plt.title(dataset)\n",
        "      plt.xlabel(\"Time (Years)\")\n",
        "      plt.ylabel(\"Survival probability\")\n",
        "      ax.grid(axis='both', which='both',color='lightgray', linestyle='-', linewidth=0.5,zorder=-1000)\n",
        "      ax.text(0.05, 0.05, \"Log Rank P-value : \"+str(round(results.p_value, 4)),bbox = {'facecolor': 'lightgray'})\n",
        "      ax.text(0.05, 0.15, \"C-index : \"+str(round(train_scores['test_score'].mean(), 2)),bbox = {'facecolor': 'lightgray'})\n",
        "      print(str(n*100/51)+\",\"+dataset+\",\"+name+\",\"+str(train_scores['test_score'].mean())+\",\"+str(train_scores['test_score'].std())+\",\"+str(results.p_value)+\",\"+str(test_test_score)+\",\"+str(test_results.p_value)+\",\"+str(train_scores))\n",
        "\n",
        "      from lifelines.plotting import add_at_risk_counts\n",
        "      add_at_risk_counts(kmf, kmf2 , ax=ax)\n",
        "      plt.savefig(result_path+\"/figs/\"+dataset+\"-\"+name+\".png\")\n",
        "\n",
        "      plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
