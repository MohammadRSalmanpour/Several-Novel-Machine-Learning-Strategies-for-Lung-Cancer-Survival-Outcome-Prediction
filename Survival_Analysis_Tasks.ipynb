{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hmhEy7ZF-2Ea",
      "metadata": {
        "id": "hmhEy7ZF-2Ea"
      },
      "outputs": [],
      "source": [
        "! pip install scikit-learn==1.1.3\n",
        "! pip install scikit-survival\n",
        "! pip install lifelines\n",
        "! pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f977029b-1d90-4aa2-9f47-e0131cbe960c",
      "metadata": {
        "id": "f977029b-1d90-4aa2-9f47-e0131cbe960c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sksurv.datasets import load_veterans_lung_cancer\n",
        "from sksurv.ensemble import RandomSurvivalForest, ComponentwiseGradientBoostingSurvivalAnalysis\n",
        "from sksurv.svm import FastSurvivalSVM\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "from sksurv.nonparametric import kaplan_meier_estimator\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines.statistics import logrank_test\n",
        "from lifelines.plotting import add_at_risk_counts\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mlp\n",
        "from lifelines import CoxPHFitter\n",
        "from hotelling.stats import hotelling_t2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WiW0bbTo-okp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiW0bbTo-okp",
        "outputId": "9b9ecf91-fe35-46f1-ba2f-4164b9b191b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c4cd379-492e-4a5c-8ea0-b09c7ec2d06a",
      "metadata": {
        "id": "8c4cd379-492e-4a5c-8ea0-b09c7ec2d06a"
      },
      "outputs": [],
      "source": [
        "# Font settings for plots\n",
        "font_size = 16\n",
        "mlp.rcParams['figure.figsize'] = (8, 6)\n",
        "mlp.rcParams['figure.labelsize'] = 'large'\n",
        "font = {'weight' : 'bold',\n",
        "        'size' : font_size}\n",
        "\n",
        "mlp.rc('font', **font)\n",
        "font_label = font_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294c12ec-e0c6-4ef1-a18a-2f644c4f4187",
      "metadata": {
        "id": "294c12ec-e0c6-4ef1-a18a-2f644c4f4187"
      },
      "outputs": [],
      "source": [
        "# The name of datasets\n",
        "dataset_names = ['LC_DF_SCT', 'LC_DF_SPT', 'LC_RF_CT',  'LC_RF_PT','LC_RF+DF_CT', 'LC_RF+DF_PT']\n",
        "result_names = ['DRF-CT', 'DRF-PET', 'HRF-CT', 'HRF-PET','HRF-PET Plus DRF-CT', 'HRF-PET Plus DRF-PET']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7481c4-44c9-49c7-a772-8df487a239b2",
      "metadata": {
        "id": "0a7481c4-44c9-49c7-a772-8df487a239b2"
      },
      "source": [
        "# Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087927c0-eafc-44a2-86b8-fad84386ff25",
      "metadata": {
        "id": "087927c0-eafc-44a2-86b8-fad84386ff25"
      },
      "outputs": [],
      "source": [
        "# Initialize HyperParametters for Random Survival Forest, Fast Survival SVM and Component-wise Gradient Boosting Survival Analysis\n",
        "\n",
        "# Random Survival Forest\n",
        "rsf = RandomSurvivalForest(n_estimators=10,\n",
        "                           min_samples_split=5,\n",
        "                           min_samples_leaf=10,\n",
        "                           max_features=\"sqrt\",\n",
        "                           n_jobs=-1,\n",
        "                           random_state=42)\n",
        "\n",
        "# Fast Survival SVM\n",
        "fssvm = FastSurvivalSVM(max_iter=512, tol=1e-6, random_state=42)\n",
        "\n",
        "# Component-wise Gradient Boosting Survival Analysis\n",
        "cwgbsa = ComponentwiseGradientBoostingSurvivalAnalysis(random_state=42)\n",
        "\n",
        "cph = CoxPHFitter(penalizer=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48196cb8-35c2-4fe7-a2e6-93fe04d73a1e",
      "metadata": {
        "id": "48196cb8-35c2-4fe7-a2e6-93fe04d73a1e"
      },
      "outputs": [],
      "source": [
        "# Split Five folds\n",
        "# Assuming X is your feature matrix and y is your target vector\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vb4IpoQE_MMC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb4IpoQE_MMC",
        "outputId": "b9c074b9-9273-4f2c-f6cb-874c34f3bc4d"
      },
      "outputs": [],
      "source": [
        "cd path_to_directy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2aa0883-a5fc-4f84-a537-1f2f9fcf63af",
      "metadata": {
        "id": "e2aa0883-a5fc-4f84-a537-1f2f9fcf63af"
      },
      "source": [
        "## 1. Random Survival Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "724a3751-a5b1-4d44-a24c-634fbc19c62e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "724a3751-a5b1-4d44-a24c-634fbc19c62e",
        "outputId": "ed955239-8cab-488e-e39e-e26fe1b658a2"
      },
      "outputs": [],
      "source": [
        "################################# Random Survival Forest #################################\n",
        "\n",
        "# Add RFS Algorithm reported Results to its Data Frame\n",
        "df_reported_results_rsf = pd.DataFrame(columns=['Dataset', 'SRA', 'Mean C-Index Internal', 'Std C-Index Internal', 'Mean C-Index External',\n",
        "                                                'Std C-Index External', '5-Folds P-Value', 'P-value External', 'Combined C-Index', 'Combined P-value'])\n",
        "\n",
        "# Compute statistics features for all datasets with RFS algorithm\n",
        "for index_name in range(6):\n",
        "\n",
        "    # Load a dataset (example: Veterans' Lung Cancer trial)\n",
        "    X = pd.read_csv(os.path.join('Data', '{}.csv'.format(str(dataset_names[index_name]))), header=None)\n",
        "    y = pd.read_csv(os.path.join('Data', 'COX_OUTCOME.csv'))\n",
        "\n",
        "    # Convert days to years\n",
        "    years = y['Duration'].astype('float') / 365\n",
        "\n",
        "    # Convert the structured array y to a boolean array\n",
        "    event = y['Censor'].astype(bool)\n",
        "    time = y['Duration'].values\n",
        "\n",
        "\n",
        "    # Prepare the data for the model\n",
        "    train_size = int(len(X) * 0.8)\n",
        "\n",
        "    # Split Data\n",
        "    X_train = X[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    event_train = event[:train_size]\n",
        "    time_train = time[:train_size]\n",
        "    event_test_external = event[train_size:]\n",
        "    time_test_external = time[train_size:]\n",
        "\n",
        "    # Dimention Reduction with PCA\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    X_train = min_max_scaler.fit_transform(X_train)\n",
        "    X_test = min_max_scaler.transform(X_test)\n",
        "\n",
        "    # Define PCA\n",
        "    pca = PCA(n_components=10)\n",
        "    X_train = pca.fit_transform(X_train)\n",
        "    X_test = pca.transform(X_test)\n",
        "\n",
        "    y_train = np.array([(e, t) for e, t in zip(event_train, time_train)],\n",
        "                        dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    y_test = np.array([(e, t) for e, t in zip(event_test_external, time_test_external)],\n",
        "                       dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    # Add Algorithm internal and external Results to its Data Frame\n",
        "    df_internal_results_rsf = pd.DataFrame(columns=['C-Index internal', 'C-Index External', 'P-Value Internal', 'P-Value External'])\n",
        "\n",
        "    # Risk Scores for 5-fold and external test\n",
        "    risk_scores_folds = []\n",
        "    risk_scores_test_external = []\n",
        "\n",
        "    # Fit the model\n",
        "    for train_index, test_index in kf.split(X_train):\n",
        "        X_train_in, X_test_in = X_train[train_index], X_train[test_index]\n",
        "        y_train_in, y_test_in = y_train[train_index], y_train[test_index]\n",
        "\n",
        "        # Determine internal Event and Time\n",
        "        event_test_internal = np.array([tup[0] for tup in y_test_in])\n",
        "        time_test_internal = np.array([tup[1] for tup in y_test_in])\n",
        "\n",
        "        # Train Model\n",
        "        rsf.fit(X_train_in, y_train_in)\n",
        "\n",
        "        ################################# Predicting survival - Internal Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_internal = rsf.predict(X_test_in)\n",
        "        for item in risk_scores_internal.tolist():\n",
        "            risk_scores_folds.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_internal = concordance_index_censored(event_test_internal, time_test_internal, risk_scores_internal)\n",
        "        c_index_internal = result_internal[0]\n",
        "\n",
        "        # Log-rank Test\n",
        "        group_labels_internal = np.random.choice([0, 1], size=X_test_in.shape[0], replace=True)  # Example groups\n",
        "        idx_internal = group_labels_internal == 1\n",
        "        time1_internal, event1_internal = time_test_internal[idx_internal], event_test_internal[idx_internal]\n",
        "        time2_internal, event2_internal = time_test_internal[~idx_internal], event_test_internal[~idx_internal]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_internal = logrank_test(time1_internal, time2_internal, event_observed_A=event1_internal, event_observed_B=event2_internal)\n",
        "        # Compute P-Value test\n",
        "        p_value_internal = test_result_internal.p_value\n",
        "\n",
        "        ################################# Predicting survival - External Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_external = rsf.predict(X_test)\n",
        "        for item in risk_scores_external.tolist():\n",
        "            risk_scores_test_external.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_external = concordance_index_censored(event_test_external, time_test_external, risk_scores_external)\n",
        "        c_index_external = result_external[0]\n",
        "\n",
        "        # Log-rank Test\n",
        "        group_labels_external = np.random.choice([0, 1], size=X_test.shape[0], replace=True)  # Example groups\n",
        "        idx_external = group_labels_external == 1\n",
        "        time1_external, event1_external = time_test_external[idx_external], event_test_external[idx_external]\n",
        "        time2_external, event2_external = time_test_external[~idx_external], event_test_external[~idx_external]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_external = logrank_test(time1_external, time2_external, event_observed_A=event1_external, event_observed_B=event2_external)\n",
        "        # Compute P-Value test\n",
        "        p_value_external = test_result_external.p_value\n",
        "\n",
        "        # Add Internal and External Results to Data Frame\n",
        "        df_internal_results_rsf.loc[len(df_internal_results_rsf)] = [c_index_internal, c_index_external, p_value_internal, p_value_external]\n",
        "\n",
        "    # Add Internal and External Results to Data Frame\n",
        "    df_internal_results_rsf.to_csv(os.path.join('Results', 'RSF_{}-Results.csv'.format(str(result_names[index_name]))))\n",
        "\n",
        "\n",
        "    ############################ P-Value #########################################################################\n",
        "\n",
        "    # Log-rank Test\n",
        "    group_labels = np.random.choice([0, 1], size=X_train.shape[0], replace=True)  # Example groups\n",
        "    idx = group_labels == 1\n",
        "    time1, event1 = time_train[idx], event_train[idx]\n",
        "    time2, event2 = time_train[~idx], event_train[~idx]\n",
        "\n",
        "    # Compute log-rank test\n",
        "    train_result = logrank_test(time1, time2, event_observed_A=event1, event_observed_B=event2)\n",
        "    # Compute P-Value test\n",
        "    p_value_train = train_result.p_value\n",
        "\n",
        "    ############################################ Save Results #####################################################\n",
        "\n",
        "    # Add C-Indexes and P-values to data frame\n",
        "    mean_cindex_internal = df_internal_results_rsf['C-Index internal'].mean()\n",
        "    std_cindex_internal = df_internal_results_rsf['C-Index internal'].std()\n",
        "    mean_cindex_external = df_internal_results_rsf['C-Index External'].mean()\n",
        "    std_cindex_external = df_internal_results_rsf['C-Index External'].std()\n",
        "    pvalue_external = df_internal_results_rsf['P-Value External'].min()\n",
        "\n",
        "    ############################################## Draw Kaplan Mier ##############################################\n",
        "\n",
        "    # Hotelling T-test\n",
        "    risk_scores_combine_for_hotelling = np.array(risk_scores_folds + risk_scores_test_external[:40])\n",
        "    threshold_for_hotelling  = np.percentile(risk_scores_combine_for_hotelling, 50)\n",
        "\n",
        "    y_for_hotelling = np.array(y_train.tolist() + y_test.tolist())\n",
        "    X_for_hotelling = np.array(X_train.tolist() + X_test.tolist())\n",
        "\n",
        "    high_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling >= threshold_for_hotelling]\n",
        "    low_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling < threshold_for_hotelling]\n",
        "\n",
        "    print(hotelling_t2(high_risk_for_h, low_risk_for_h)[2])\n",
        "\n",
        "    # Determine high and low risk groups\n",
        "    risk_scores_combined = np.array(risk_scores_folds + risk_scores_test_external)\n",
        "\n",
        "    threshold = np.percentile(risk_scores_combined, 50)\n",
        "\n",
        "    y_combined = np.array(y_train.tolist() + (y_test.tolist() * 5))\n",
        "\n",
        "    high_risk = y_combined[risk_scores_combined >= threshold]\n",
        "    low_risk = y_combined[risk_scores_combined < threshold]\n",
        "\n",
        "\n",
        "\n",
        "    high_risk_event = np.array([tup[0] for tup in high_risk])\n",
        "    high_risk_time = np.array([tup[1] for tup in high_risk])\n",
        "    low_risk_event = np.array([tup[0] for tup in low_risk])\n",
        "    low_risk_time = np.array([tup[1] for tup in low_risk])\n",
        "\n",
        "    if len(low_risk) > 0 and len(high_risk) > 0:\n",
        "        # Calculate the Kaplan-Meier estimates for the two groups\n",
        "        time_high, survival_prob_high = kaplan_meier_estimator(high_risk_event.astype(bool), high_risk_time)\n",
        "        time_low, survival_prob_low = kaplan_meier_estimator(low_risk_event.astype(bool), low_risk_time)\n",
        "\n",
        "        # Compute P-value combined data\n",
        "        results_pvalue_combined = logrank_test(low_risk_time, high_risk_time,\n",
        "                                               event_observed_A=low_risk_event, event_observed_B=high_risk_event)\n",
        "        pvalue_combined = results_pvalue_combined.p_value\n",
        "\n",
        "        # Compute c-index combined data\n",
        "        event_combined = np.array([tup[0] for tup in y_combined])\n",
        "        time_combined = np.array([tup[1] for tup in y_combined])\n",
        "        results_cindex_combined = concordance_index_censored(event_combined.astype(bool), time_combined, risk_scores_combined)\n",
        "        c_index_combined = results_cindex_combined[0]\n",
        "        plt.clf()\n",
        "\n",
        "        kmf1 = KaplanMeierFitter()\n",
        "        kmf2 = KaplanMeierFitter()\n",
        "\n",
        "        kmf1.fit(high_risk_time.astype('float') / 365, high_risk_event, label='High Risk')\n",
        "\n",
        "        kmf2.fit(low_risk_time.astype('float') / 365, low_risk_event, label='Low Risk')\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = plt.subplot(111)\n",
        "\n",
        "        ax = kmf1.plot(color='r', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "        ax = kmf2.plot(color='g', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "\n",
        "        plt.title(\"RSF , \"+result_names[index_name], fontsize=font_label, fontweight='bold')\n",
        "\n",
        "        plt.xlabel(\"Time (Years)\", fontsize=font_label, fontweight='bold')\n",
        "        plt.ylabel(\"Survival probability\", fontsize=font_label, fontweight='bold')\n",
        "        plt.xticks(np.arange(int(years.min()), int(years.max()) + 1, 1.0))\n",
        "        ax.grid(axis='both', which='both', color='lightgray', linestyle='-', linewidth=0.5, zorder=-1000)\n",
        "        # ax.text(0, 0, \"Log Rank P-value : \"+str(round(pvalue_combined, 4)),bbox = {'facecolor': 'lightgray'})\n",
        "        # ax.text(0, 0, \"C-index : \"+str(round(c_index_combined, 2)),bbox = {'facecolor': 'lightgray'})\n",
        "\n",
        "\n",
        "\n",
        "        fig.savefig(os.path.join('Plots', 'RSF_{}-KaplanMier.jpg'.format(str(result_names[index_name]))), dpi=300)\n",
        "\n",
        "    #########################################################################################################\n",
        "\n",
        "    # Add Reported Results to its Data Frame\n",
        "    df_reported_results_rsf.loc[len(df_reported_results_rsf)] = [result_names[index_name], 'RSF', mean_cindex_internal, std_cindex_internal,\n",
        "                                                                 mean_cindex_external, std_cindex_external, p_value_train, pvalue_external,\n",
        "                                                                 c_index_combined, pvalue_combined]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1514ca5d-fb3d-426b-a929-749bab17d779",
      "metadata": {
        "id": "1514ca5d-fb3d-426b-a929-749bab17d779"
      },
      "source": [
        "## Fast Survival SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46de60be-e4e4-449a-9ef2-f171d6577cf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "46de60be-e4e4-449a-9ef2-f171d6577cf8",
        "outputId": "b9b847b5-e690-4577-eabb-88e98f10b416"
      },
      "outputs": [],
      "source": [
        "################################# Random Survival Forest #################################\n",
        "\n",
        "# Data Frame for Add RFS Algorithm reported Results\n",
        "df_reported_results_fssvm = pd.DataFrame(columns=['Dataset', 'SRA', 'Mean C-Index Internal', 'Std C-Index Internal', 'Mean C-Index External',\n",
        "                                                  'Std C-Index External', '5-Folds P-Value', 'P-value External', 'Combined C-Index', 'Combined P-value'])\n",
        "\n",
        "# Compute statistics features for all datasets with RFS algorithm\n",
        "for index_name in range(6):\n",
        "    # Load a dataset (example: Veterans' Lung Cancer trial)\n",
        "    X = pd.read_csv(os.path.join('Data', '{}.csv'.format(str(dataset_names[index_name]))), header=None)\n",
        "    y = pd.read_csv(os.path.join('Data', 'COX_OUTCOME.csv'))\n",
        "\n",
        "    # Convert days to years\n",
        "    years = y['Duration'].astype('float') / 365\n",
        "\n",
        "        # Convert the structured array y to a boolean array\n",
        "    event = y['Censor'].astype(bool)\n",
        "    time = y['Duration'].values\n",
        "\n",
        "\n",
        "    # Prepare the data for the model\n",
        "    train_size = int(len(X) * 0.8)\n",
        "\n",
        "    # Split Data\n",
        "    X_train = X[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    event_train = event[:train_size]\n",
        "    time_train = time[:train_size]\n",
        "    event_test_external = event[train_size:]\n",
        "    time_test_external = time[train_size:]\n",
        "\n",
        "    # Dimention Reduction with PCA\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    X_train = min_max_scaler.fit_transform(X_train)\n",
        "    X_test = min_max_scaler.transform(X_test)\n",
        "\n",
        "    # Define PCA\n",
        "    pca = PCA(n_components=10)\n",
        "    X_train = pca.fit_transform(X_train)\n",
        "    X_test = pca.transform(X_test)\n",
        "\n",
        "    y_train = np.array([(e, t) for e, t in zip(event_train, time_train)],\n",
        "                        dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    y_test = np.array([(e, t) for e, t in zip(event_test_external, time_test_external)],\n",
        "                       dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    # Add Algorithm internal and external Results to its Data Frame\n",
        "    df_internal_results_fssvm = pd.DataFrame(columns=['C-Index internal', 'C-Index External', 'P-Value Internal', 'P-Value External'])\n",
        "\n",
        "    # Risk Scores for 5-fold and external test\n",
        "    risk_scores_folds = []\n",
        "    risk_scores_test_external = []\n",
        "\n",
        "    # Fit the model\n",
        "    for train_index, test_index in kf.split(X_train):\n",
        "        X_train_in, X_test_in = X_train[train_index], X_train[test_index]\n",
        "        y_train_in, y_test_in = y_train[train_index], y_train[test_index]\n",
        "\n",
        "        # Determine internal Event and Time\n",
        "        event_test_internal = np.array([tup[0] for tup in y_test_in])\n",
        "        time_test_internal = np.array([tup[1] for tup in y_test_in])\n",
        "\n",
        "        # Train Model\n",
        "        fssvm.fit(X_train_in, y_train_in)\n",
        "\n",
        "        ################################# Predicting survival - Internal Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_internal = fssvm.predict(X_test_in)\n",
        "        for item in risk_scores_internal.tolist():\n",
        "            risk_scores_folds.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_internal = concordance_index_censored(event_test_internal, time_test_internal, risk_scores_internal)\n",
        "        c_index_internal = result_internal[0]\n",
        "\n",
        "        # Log-rank Test\n",
        "        group_labels_internal = np.random.choice([0, 1], size=X_test_in.shape[0], replace=True)  # Example groups\n",
        "        idx_internal = group_labels_internal == 1\n",
        "        time1_internal, event1_internal = time_test_internal[idx_internal], event_test_internal[idx_internal]\n",
        "        time2_internal, event2_internal = time_test_internal[~idx_internal], event_test_internal[~idx_internal]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_internal = logrank_test(time1_internal, time2_internal, event_observed_A=event1_internal, event_observed_B=event2_internal)\n",
        "        # Compute P-Value test\n",
        "        p_value_internal = test_result_internal.p_value\n",
        "\n",
        "        ################################# Predicting survival - External Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_external = fssvm.predict(X_test)\n",
        "        for item in risk_scores_external.tolist():\n",
        "            risk_scores_test_external.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_external = concordance_index_censored(event_test_external, time_test_external, risk_scores_external)\n",
        "        c_index_external = result_external[0]\n",
        "\n",
        "        # Log-rank Test\n",
        "        group_labels_external = np.random.choice([0, 1], size=X_test.shape[0], replace=True)  # Example groups\n",
        "        idx_external = group_labels_external == 1\n",
        "        time1_external, event1_external = time_test_external[idx_external], event_test_external[idx_external]\n",
        "        time2_external, event2_external = time_test_external[~idx_external], event_test_external[~idx_external]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_external = logrank_test(time1_external, time2_external, event_observed_A=event1_external, event_observed_B=event2_external)\n",
        "        # Compute P-Value test\n",
        "        p_value_external = test_result_external.p_value\n",
        "\n",
        "        # Add Internal and External Results to Data Frame\n",
        "        df_internal_results_fssvm.loc[len(df_internal_results_fssvm)] = [c_index_internal, c_index_external, p_value_internal, p_value_external]\n",
        "\n",
        "    # Add Internal and External Results to Data Frame\n",
        "    # df_internal_results_fssvm.to_csv(os.path.join('Results', 'FSSVM_{}-Results.csv'.format(str(result_names[index_name]))))\n",
        "\n",
        "\n",
        "    ############################ P-Value #########################################################################\n",
        "\n",
        "    # Log-rank Test\n",
        "    group_labels = np.random.choice([0, 1], size=X_train.shape[0], replace=True)  # Example groups\n",
        "    idx = group_labels == 1\n",
        "    time1, event1 = time_train[idx], event_train[idx]\n",
        "    time2, event2 = time_train[~idx], event_train[~idx]\n",
        "\n",
        "    # Compute log-rank test\n",
        "    train_result = logrank_test(time1, time2, event_observed_A=event1, event_observed_B=event2)\n",
        "    # Compute P-Value test\n",
        "    p_value_train = train_result.p_value\n",
        "\n",
        "    ############################################ Save Results #####################################################\n",
        "\n",
        "    # Add C-Indexes and P-values to its Data Frame\n",
        "    mean_cindex_internal = df_internal_results_fssvm['C-Index internal'].mean()\n",
        "    std_cindex_internal = df_internal_results_fssvm['C-Index internal'].std()\n",
        "    mean_cindex_external = df_internal_results_fssvm['C-Index External'].mean()\n",
        "    std_cindex_external = df_internal_results_fssvm['C-Index External'].std()\n",
        "    pvalue_external = df_internal_results_fssvm['P-Value External'].min()\n",
        "\n",
        "    ############################################## Draw Kaplan Mier ##############################################\n",
        "    # Hotelling T-test\n",
        "    risk_scores_combine_for_hotelling = np.array(risk_scores_folds + risk_scores_test_external[:40])\n",
        "    threshold_for_hotelling  = np.percentile(risk_scores_combine_for_hotelling, 50)\n",
        "\n",
        "    y_for_hotelling = np.array(y_train.tolist() + y_test.tolist())\n",
        "    X_for_hotelling = np.array(X_train.tolist() + X_test.tolist())\n",
        "\n",
        "    high_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling >= threshold_for_hotelling]\n",
        "    low_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling < threshold_for_hotelling]\n",
        "\n",
        "    print(hotelling_t2(high_risk_for_h, low_risk_for_h)[2])\n",
        "\n",
        "    # Determine high and low risk groups\n",
        "    risk_scores_combined = np.array(risk_scores_folds + risk_scores_test_external)\n",
        "    threshold = np.percentile(risk_scores_combined, 50)\n",
        "\n",
        "    y_combined = np.array(y_train.tolist() + (y_test.tolist() * 5))\n",
        "\n",
        "    high_risk = y_combined[risk_scores_combined >= threshold]\n",
        "    low_risk = y_combined[risk_scores_combined < threshold]\n",
        "\n",
        "    high_risk_event = np.array([tup[0] for tup in high_risk])\n",
        "    high_risk_time = np.array([tup[1] for tup in high_risk])\n",
        "    low_risk_event = np.array([tup[0] for tup in low_risk])\n",
        "    low_risk_time = np.array([tup[1] for tup in low_risk])\n",
        "\n",
        "    if len(low_risk) > 0 and len(high_risk) > 0:\n",
        "        # Calculate the Kaplan-Meier estimates for the two groups\n",
        "        time_high, survival_prob_high = kaplan_meier_estimator(high_risk_event.astype(bool), high_risk_time)\n",
        "        time_low, survival_prob_low = kaplan_meier_estimator(low_risk_event.astype(bool), low_risk_time)\n",
        "\n",
        "        # Compute P-value combined data\n",
        "        results_pvalue_combined = logrank_test(low_risk_time, high_risk_time,\n",
        "                                               event_observed_A=low_risk_event, event_observed_B=high_risk_event)\n",
        "        pvalue_combined = results_pvalue_combined.p_value\n",
        "\n",
        "        # Compute c-index combined data\n",
        "        event_combined = np.array([tup[0] for tup in y_combined])\n",
        "        time_combined = np.array([tup[1] for tup in y_combined])\n",
        "        results_cindex_combined = concordance_index_censored(event_combined.astype(bool), time_combined, risk_scores_combined)\n",
        "        c_index_combined = results_cindex_combined[0]\n",
        "\n",
        "        kmf1 = KaplanMeierFitter()\n",
        "        kmf2 = KaplanMeierFitter()\n",
        "\n",
        "        kmf1.fit(high_risk_time.astype('float') / 365, high_risk_event, label='High Risk')\n",
        "\n",
        "        kmf2.fit(low_risk_time.astype('float') / 365, low_risk_event, label='Low Risk')\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "\n",
        "        ax = kmf1.plot(color='r', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "        ax = kmf2.plot(color='g', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "        plt.title(\"FSVM , \"+result_names[index_name], fontsize=font_label, fontweight='bold')\n",
        "        plt.xlabel(\"Time (Years)\", fontsize=font_label, fontweight='bold')\n",
        "        plt.ylabel(\"Survival probability\", fontsize=font_label, fontweight='bold')\n",
        "        plt.xticks(np.arange(int(years.min()), int(years.max()) + 1, 1.0))\n",
        "        ax.grid(axis='both', which='both', color='lightgray', linestyle='-', linewidth=0.5,zorder=-1000)\n",
        "\n",
        "        # add_at_risk_counts(kmf1, kmf2 , ax=ax)\n",
        "        # plt.tight_layout()\n",
        "\n",
        "        fig.savefig(os.path.join('Plots', 'FSSVM_{}-KaplanMier.jpg'.format(str(result_names[index_name]))), dpi=300)\n",
        "\n",
        "    #########################################################################################################\n",
        "\n",
        "    # Add Reported Results to its Data Frame\n",
        "    df_reported_results_fssvm.loc[len(df_reported_results_fssvm)] = [result_names[index_name], 'FSSVM', mean_cindex_internal, std_cindex_internal,\n",
        "                                                                     mean_cindex_external, std_cindex_external, p_value_train, pvalue_external,\n",
        "                                                                     c_index_combined, pvalue_combined]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1307e48-8b68-4850-8ba3-d8c5f97179bd",
      "metadata": {
        "id": "c1307e48-8b68-4850-8ba3-d8c5f97179bd"
      },
      "source": [
        "## Component-wise Gradient Boosting Survival Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8a141c-5f01-45ac-9d52-3717ee5a3c65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fc8a141c-5f01-45ac-9d52-3717ee5a3c65",
        "outputId": "b3f4522d-79df-4406-f056-3ce093c7859e"
      },
      "outputs": [],
      "source": [
        "################################# Random Survival Forest #################################\n",
        "\n",
        "# Data Frame for Add RFS Algorithm reported Results\n",
        "df_reported_results_cwgbsa = pd.DataFrame(columns=['Dataset', 'SRA', 'Mean C-Index Internal', 'Std C-Index Internal', 'Mean C-Index External',\n",
        "                                                   'Std C-Index External', '5-Folds P-Value', 'P-value External', 'Combined C-Index', 'Combined P-value'])\n",
        "\n",
        "# Compute statistics features for all datasets with RFS algorithm\n",
        "for index_name in range(6):\n",
        "    # Load a dataset (example: Veterans' Lung Cancer trial)\n",
        "    X = pd.read_csv(os.path.join('Data', '{}.csv'.format(str(dataset_names[index_name]))), header=None)\n",
        "    y = pd.read_csv(os.path.join('Data', 'COX_OUTCOME.csv'))\n",
        "\n",
        "    # Convert days to years\n",
        "    years = y['Duration'].astype('float') / 365\n",
        "\n",
        "    # Convert the structured array y to a boolean array\n",
        "    event = y['Censor'].astype(bool)\n",
        "    time = y['Duration'].values\n",
        "\n",
        "\n",
        "    # Prepare the data for the model\n",
        "    train_size = int(len(X) * 0.8)\n",
        "\n",
        "    # Split Data\n",
        "    X_train = X[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    event_train = event[:train_size]\n",
        "    time_train = time[:train_size]\n",
        "    event_test_external = event[train_size:]\n",
        "    time_test_external = time[train_size:]\n",
        "\n",
        "    # Dimention Reduction with PCA\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    X_train = min_max_scaler.fit_transform(X_train)\n",
        "    X_test = min_max_scaler.transform(X_test)\n",
        "\n",
        "    # Define PCA\n",
        "    pca = PCA(n_components=10)\n",
        "    X_train = pca.fit_transform(X_train)\n",
        "    X_test = pca.transform(X_test)\n",
        "\n",
        "    y_train = np.array([(e, t) for e, t in zip(event_train, time_train)],\n",
        "                        dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    y_test = np.array([(e, t) for e, t in zip(event_test_external, time_test_external)],\n",
        "                       dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    # Add Algorithm internal and external Results to its Data Frame\n",
        "    df_internal_results_cwgbsa = pd.DataFrame(columns=['C-Index internal', 'C-Index External', 'P-Value Internal', 'P-Value External'])\n",
        "\n",
        "    # Risk Scores for 5-fold and external test\n",
        "    risk_scores_folds = []\n",
        "    risk_scores_test_external = []\n",
        "\n",
        "    # Fit the model\n",
        "    for train_index, test_index in kf.split(X_train):\n",
        "        X_train_in, X_test_in = X_train[train_index], X_train[test_index]\n",
        "        y_train_in, y_test_in = y_train[train_index], y_train[test_index]\n",
        "\n",
        "        # Determine internal Event and Time\n",
        "        event_test_internal = np.array([tup[0] for tup in y_test_in])\n",
        "        time_test_internal = np.array([tup[1] for tup in y_test_in])\n",
        "\n",
        "        # Train Model\n",
        "        cwgbsa.fit(X_train_in, y_train_in)\n",
        "\n",
        "        ################################# Predicting survival - Internal Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_internal = cwgbsa.predict(X_test_in)\n",
        "        for item in risk_scores_internal.tolist():\n",
        "            risk_scores_folds.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_internal = concordance_index_censored(event_test_internal, time_test_internal, risk_scores_internal)\n",
        "        c_index_internal = result_internal[0]\n",
        "\n",
        "        # Log-rank Test\n",
        "        group_labels_internal = np.random.choice([0, 1], size=X_test_in.shape[0], replace=True)  # Example groups\n",
        "        idx_internal = group_labels_internal == 1\n",
        "        time1_internal, event1_internal = time_test_internal[idx_internal], event_test_internal[idx_internal]\n",
        "        time2_internal, event2_internal = time_test_internal[~idx_internal], event_test_internal[~idx_internal]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_internal = logrank_test(time1_internal, time2_internal, event_observed_A=event1_internal, event_observed_B=event2_internal)\n",
        "        # Compute P-Value test\n",
        "        p_value_internal = test_result_internal.p_value\n",
        "\n",
        "        ################################# Predicting survival - External Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_external = cwgbsa.predict(X_test)\n",
        "        for item in risk_scores_external.tolist():\n",
        "            risk_scores_test_external.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_external = concordance_index_censored(event_test_external, time_test_external, risk_scores_external)\n",
        "        c_index_external = result_external[0]\n",
        "\n",
        "        # Log-rank Test (Example for two hypothetical groups)\n",
        "        group_labels_external = np.random.choice([0, 1], size=X_test.shape[0], replace=True)  # Example groups\n",
        "        idx_external = group_labels_external == 1\n",
        "        time1_external, event1_external = time_test_external[idx_external], event_test_external[idx_external]\n",
        "        time2_external, event2_external = time_test_external[~idx_external], event_test_external[~idx_external]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_external = logrank_test(time1_external, time2_external, event_observed_A=event1_external, event_observed_B=event2_external)\n",
        "        # Compute P-Value test\n",
        "        p_value_external = test_result_external.p_value\n",
        "\n",
        "        # Add Internal and External Results to Data Frame\n",
        "        df_internal_results_cwgbsa.loc[len(df_internal_results_cwgbsa)] = [c_index_internal, c_index_external, p_value_internal, p_value_external]\n",
        "\n",
        "    # Add Internal and External Results to Data Frame\n",
        "    # df_internal_results_cwgbsa.to_csv(os.path.join('Results', 'CWGBSA_{}-Results.csv'.format(str(result_names[index_name]))))\n",
        "\n",
        "\n",
        "    ############################ P-Value #########################################################################\n",
        "\n",
        "    # Log-rank Test\n",
        "    group_labels = np.random.choice([0, 1], size=X_train.shape[0], replace=True)  # Example groups\n",
        "    idx = group_labels == 1\n",
        "    time1, event1 = time_train[idx], event_train[idx]\n",
        "    time2, event2 = time_train[~idx], event_train[~idx]\n",
        "\n",
        "    # Compute log-rank test\n",
        "    train_result = logrank_test(time1, time2, event_observed_A=event1, event_observed_B=event2)\n",
        "    # Compute P-Value test\n",
        "    p_value_train = train_result.p_value\n",
        "\n",
        "    ############################################ Save Results #####################################################\n",
        "\n",
        "    # Add C-Indexes and P-values to its Data Frame\n",
        "    mean_cindex_internal = df_internal_results_cwgbsa['C-Index internal'].mean()\n",
        "    std_cindex_internal = df_internal_results_cwgbsa['C-Index internal'].std()\n",
        "    mean_cindex_external = df_internal_results_cwgbsa['C-Index External'].mean()\n",
        "    std_cindex_external = df_internal_results_cwgbsa['C-Index External'].std()\n",
        "    pvalue_external = df_internal_results_cwgbsa['P-Value External'].min()\n",
        "\n",
        "    ############################################## Draw Kaplan Mier ##############################################\n",
        "    # Hotelling T-test\n",
        "    risk_scores_combine_for_hotelling = np.array(risk_scores_folds + risk_scores_test_external[:40])\n",
        "    threshold_for_hotelling  = np.percentile(risk_scores_combine_for_hotelling, 50)\n",
        "\n",
        "    y_for_hotelling = np.array(y_train.tolist() + y_test.tolist())\n",
        "    X_for_hotelling = np.array(X_train.tolist() + X_test.tolist())\n",
        "\n",
        "    high_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling >= threshold_for_hotelling]\n",
        "    low_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling < threshold_for_hotelling]\n",
        "\n",
        "    print(hotelling_t2(high_risk_for_h, low_risk_for_h)[2])\n",
        "\n",
        "    # Determine high and low risk groups\n",
        "    risk_scores_combined = np.array(risk_scores_folds + risk_scores_test_external)\n",
        "    threshold = np.percentile(risk_scores_combined, 50)\n",
        "\n",
        "    y_combined = np.array(y_train.tolist() + (y_test.tolist() * 5))\n",
        "\n",
        "    high_risk = y_combined[risk_scores_combined >= threshold]\n",
        "    low_risk = y_combined[risk_scores_combined < threshold]\n",
        "\n",
        "    high_risk_event = np.array([tup[0] for tup in high_risk])\n",
        "    high_risk_time = np.array([tup[1] for tup in high_risk])\n",
        "    low_risk_event = np.array([tup[0] for tup in low_risk])\n",
        "    low_risk_time = np.array([tup[1] for tup in low_risk])\n",
        "\n",
        "    if len(low_risk) > 0 and len(high_risk) > 0:\n",
        "        # Calculate the Kaplan-Meier estimates for the two groups\n",
        "        time_high, survival_prob_high = kaplan_meier_estimator(high_risk_event.astype(bool), high_risk_time)\n",
        "        time_low, survival_prob_low = kaplan_meier_estimator(low_risk_event.astype(bool), low_risk_time)\n",
        "\n",
        "        # Compute P-value combined data\n",
        "        results_pvalue_combined = logrank_test(low_risk_time, high_risk_time,\n",
        "                                               event_observed_A=low_risk_event, event_observed_B=high_risk_event)\n",
        "        pvalue_combined = results_pvalue_combined.p_value\n",
        "\n",
        "        # Compute c-index combined data\n",
        "        event_combined = np.array([tup[0] for tup in y_combined])\n",
        "        time_combined = np.array([tup[1] for tup in y_combined])\n",
        "        results_cindex_combined = concordance_index_censored(event_combined.astype(bool), time_combined, risk_scores_combined)\n",
        "        c_index_combined = results_cindex_combined[0]\n",
        "\n",
        "        kmf1 = KaplanMeierFitter()\n",
        "        kmf2 = KaplanMeierFitter()\n",
        "\n",
        "        kmf1.fit(high_risk_time.astype('float') / 365, high_risk_event, label='High Risk')\n",
        "\n",
        "        kmf2.fit(low_risk_time.astype('float') / 365, low_risk_event, label='Low Risk')\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "\n",
        "        ax = kmf1.plot(color='r', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "        ax = kmf2.plot(color='g', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "        plt.title(\"CWGB , \"+result_names[index_name], fontsize=font_label, fontweight='bold')\n",
        "        plt.xlabel(\"Time (Years)\", fontsize=font_label, fontweight='bold')\n",
        "        plt.ylabel(\"Survival probability\", fontsize=font_label, fontweight='bold')\n",
        "        plt.xticks(np.arange(int(years.min()), int(years.max()) + 1, 1.0))\n",
        "        plt.yticks(np.arange(0.0, 1.0, 0.1))\n",
        "        ax.grid(axis='both', which='both', color='lightgray', linestyle='-', linewidth=0.5,zorder=-1000)\n",
        "\n",
        "        # add_at_risk_counts(kmf1, kmf2 , ax=ax)\n",
        "        # plt.tight_layout()\n",
        "\n",
        "        fig.savefig(os.path.join('Plots', 'CWGBSA_{}-KaplanMier.jpg'.format(str(result_names[index_name]))), dpi=300)\n",
        "\n",
        "    #########################################################################################################\n",
        "\n",
        "    # Add Reported Results to its Data Frame\n",
        "    df_reported_results_cwgbsa.loc[len(df_reported_results_cwgbsa)] = [result_names[index_name], 'CWGBSA', mean_cindex_internal, std_cindex_internal,\n",
        "                                                                       mean_cindex_external, std_cindex_external, p_value_train, pvalue_external,\n",
        "                                                                       c_index_combined, pvalue_combined]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IPDUjT0diQ1F",
      "metadata": {
        "id": "IPDUjT0diQ1F"
      },
      "source": [
        "##CoxPH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MHwmSPNrT_RN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MHwmSPNrT_RN",
        "outputId": "b3761537-773d-433f-c0f2-e6ce5c38547b"
      },
      "outputs": [],
      "source": [
        "################################# Random Survival Forest #################################\n",
        "\n",
        "# Data Frame for Add RFS Algorithm reported Results\n",
        "df_reported_results_cph = pd.DataFrame(columns=['Dataset', 'SRA', 'Mean C-Index Internal', 'Std C-Index Internal', 'Mean C-Index External',\n",
        "                                                   'Std C-Index External', '5-Folds P-Value', 'P-value External', 'Combined C-Index', 'Combined P-value'])\n",
        "\n",
        "# Compute statistics features for all datasets with RFS algorithm\n",
        "for index_name in range(6):\n",
        "    # Load a dataset (example: Veterans' Lung Cancer trial)\n",
        "    X = pd.read_csv(os.path.join('Data', '{}.csv'.format(str(dataset_names[index_name]))), header=None)\n",
        "    y = pd.read_csv(os.path.join('Data', 'COX_OUTCOME.csv'))\n",
        "\n",
        "    # Convert days to years\n",
        "    years = y['Duration'].astype('float') / 365\n",
        "\n",
        "    # Convert the structured array y to a boolean array\n",
        "    event = y['Censor'].astype(bool)\n",
        "    time = y['Duration'].values\n",
        "\n",
        "\n",
        "    # Prepare the data for the model\n",
        "    train_size = int(len(X) * 0.8)\n",
        "\n",
        "    # Split Data\n",
        "    X_train = X[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    event_train = event[:train_size]\n",
        "    time_train = time[:train_size]\n",
        "    event_test_external = event[train_size:]\n",
        "    time_test_external = time[train_size:]\n",
        "\n",
        "    # Dimention Reduction with PCA\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    X_train = min_max_scaler.fit_transform(X_train)\n",
        "    X_test = min_max_scaler.transform(X_test)\n",
        "\n",
        "    # Define PCA\n",
        "    pca = PCA(n_components=10)\n",
        "    X_train = pca.fit_transform(X_train)\n",
        "    X_test = pca.transform(X_test)\n",
        "\n",
        "    y_train = np.array([(e, t) for e, t in zip(event_train, time_train)],\n",
        "                        dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    y_test = np.array([(e, t) for e, t in zip(event_test_external, time_test_external)],\n",
        "                       dtype=[('Censor', bool), ('Duration', float)])\n",
        "\n",
        "    # Add Algorithm internal and external Results to its Data Frame\n",
        "    df_internal_results_cph = pd.DataFrame(columns=['C-Index internal', 'C-Index External', 'P-Value Internal', 'P-Value External'])\n",
        "\n",
        "    # Risk Scores for 5-fold and external test\n",
        "    risk_scores_folds = []\n",
        "    risk_scores_test_external = []\n",
        "\n",
        "    # Fit the model\n",
        "    for train_index, test_index in kf.split(X_train):\n",
        "        X_train_in, X_test_in = X_train[train_index], X_train[test_index]\n",
        "        y_train_in, y_test_in = y_train[train_index], y_train[test_index]\n",
        "\n",
        "        # Determine internal Event and Time\n",
        "        event_test_internal = np.array([tup[0] for tup in y_test_in])\n",
        "        time_test_internal = np.array([tup[1] for tup in y_test_in])\n",
        "\n",
        "        # Initialize and fit the Cox Proportional Hazards model\n",
        "        cph.fit(pd.concat([pd.DataFrame(X_train_in), pd.DataFrame(y_train_in)],axis=1), duration_col='Duration', event_col='Censor')\n",
        "\n",
        "        ################################# Predicting survival - Internal Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_internal = cph.predict_partial_hazard(X_test_in)\n",
        "        for item in risk_scores_internal.tolist():\n",
        "            risk_scores_folds.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_internal = concordance_index_censored(event_test_internal, time_test_internal, risk_scores_internal)\n",
        "        c_index_internal = result_internal[0]\n",
        "\n",
        "        # Log-rank Test\n",
        "        group_labels_internal = np.random.choice([0, 1], size=X_test_in.shape[0], replace=True)  # Example groups\n",
        "        idx_internal = group_labels_internal == 1\n",
        "        time1_internal, event1_internal = time_test_internal[idx_internal], event_test_internal[idx_internal]\n",
        "        time2_internal, event2_internal = time_test_internal[~idx_internal], event_test_internal[~idx_internal]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_internal = logrank_test(time1_internal, time2_internal, event_observed_A=event1_internal, event_observed_B=event2_internal)\n",
        "        # Compute P-Value test\n",
        "        p_value_internal = test_result_internal.p_value\n",
        "\n",
        "        ################################# Predicting survival - External Test #################################\n",
        "\n",
        "        # Predict\n",
        "        risk_scores_external = cph.predict_partial_hazard(X_test)\n",
        "        for item in risk_scores_external.tolist():\n",
        "            risk_scores_test_external.append(item)\n",
        "\n",
        "        # C-Index\n",
        "        result_external = concordance_index_censored(event_test_external, time_test_external, risk_scores_external)\n",
        "        c_index_external = result_external[0]\n",
        "\n",
        "        # Log-rank Test (Example for two hypothetical groups)\n",
        "        group_labels_external = np.random.choice([0, 1], size=X_test.shape[0], replace=True)  # Example groups\n",
        "        idx_external = group_labels_external == 1\n",
        "        time1_external, event1_external = time_test_external[idx_external], event_test_external[idx_external]\n",
        "        time2_external, event2_external = time_test_external[~idx_external], event_test_external[~idx_external]\n",
        "\n",
        "        # Compute log-rank test\n",
        "        test_result_external = logrank_test(time1_external, time2_external, event_observed_A=event1_external, event_observed_B=event2_external)\n",
        "        # Compute P-Value test\n",
        "        p_value_external = test_result_external.p_value\n",
        "\n",
        "        # Add Internal and External Results to Data Frame\n",
        "        df_internal_results_cph.loc[len(df_internal_results_cph)] = [c_index_internal, c_index_external, p_value_internal, p_value_external]\n",
        "\n",
        "    # Add Internal and External Results to Data Frame\n",
        "    df_internal_results_cph.to_csv(os.path.join('Results', 'cph_{}-Results.csv'.format(str(result_names[index_name]))))\n",
        "\n",
        "\n",
        "    ############################ P-Value #########################################################################\n",
        "\n",
        "    # Log-rank Test\n",
        "    group_labels = np.random.choice([0, 1], size=X_train.shape[0], replace=True)  # Example groups\n",
        "    idx = group_labels == 1\n",
        "    time1, event1 = time_train[idx], event_train[idx]\n",
        "    time2, event2 = time_train[~idx], event_train[~idx]\n",
        "\n",
        "    # Compute log-rank test\n",
        "    train_result = logrank_test(time1, time2, event_observed_A=event1, event_observed_B=event2)\n",
        "    # Compute P-Value test\n",
        "    p_value_train = train_result.p_value\n",
        "\n",
        "    ############################################ Save Results #####################################################\n",
        "\n",
        "    # Add C-Indexes and P-values to its Data Frame\n",
        "    mean_cindex_internal = df_internal_results_cph['C-Index internal'].mean()\n",
        "    std_cindex_internal = df_internal_results_cph['C-Index internal'].std()\n",
        "    mean_cindex_external = df_internal_results_cph['C-Index External'].mean()\n",
        "    std_cindex_external = df_internal_results_cph['C-Index External'].std()\n",
        "    pvalue_external = df_internal_results_cph['P-Value External'].min()\n",
        "\n",
        "    ############################################## Draw Kaplan Mier ##############################################\n",
        "    # Hotelling T-test\n",
        "    risk_scores_combine_for_hotelling = np.array(risk_scores_folds + risk_scores_test_external[:40])\n",
        "    threshold_for_hotelling  = np.percentile(risk_scores_combine_for_hotelling, 50)\n",
        "\n",
        "    y_for_hotelling = np.array(y_train.tolist() + y_test.tolist())\n",
        "    X_for_hotelling = np.array(X_train.tolist() + X_test.tolist())\n",
        "\n",
        "    high_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling >= threshold_for_hotelling]\n",
        "    low_risk_for_h = X_for_hotelling[risk_scores_combine_for_hotelling < threshold_for_hotelling]\n",
        "\n",
        "    print(hotelling_t2(high_risk_for_h, low_risk_for_h)[2])\n",
        "    # Determine high and low risk groups\n",
        "    risk_scores_combined = np.array(risk_scores_folds + risk_scores_test_external)\n",
        "    threshold = np.percentile(risk_scores_combined, 50)\n",
        "\n",
        "    y_combined = np.array(y_train.tolist() + (y_test.tolist() * 5))\n",
        "\n",
        "    high_risk = y_combined[risk_scores_combined >= threshold]\n",
        "    low_risk = y_combined[risk_scores_combined < threshold]\n",
        "\n",
        "    high_risk_event = np.array([tup[0] for tup in high_risk])\n",
        "    high_risk_time = np.array([tup[1] for tup in high_risk])\n",
        "    low_risk_event = np.array([tup[0] for tup in low_risk])\n",
        "    low_risk_time = np.array([tup[1] for tup in low_risk])\n",
        "\n",
        "    if len(low_risk) > 0 and len(high_risk) > 0:\n",
        "        # Calculate the Kaplan-Meier estimates for the two groups\n",
        "        time_high, survival_prob_high = kaplan_meier_estimator(high_risk_event.astype(bool), high_risk_time)\n",
        "        time_low, survival_prob_low = kaplan_meier_estimator(low_risk_event.astype(bool), low_risk_time)\n",
        "\n",
        "        # Compute P-value combined data\n",
        "        results_pvalue_combined = logrank_test(low_risk_time, high_risk_time,\n",
        "                                               event_observed_A=low_risk_event, event_observed_B=high_risk_event)\n",
        "        pvalue_combined = results_pvalue_combined.p_value\n",
        "\n",
        "        # Compute c-index combined data\n",
        "        event_combined = np.array([tup[0] for tup in y_combined])\n",
        "        time_combined = np.array([tup[1] for tup in y_combined])\n",
        "        results_cindex_combined = concordance_index_censored(event_combined.astype(bool), time_combined, risk_scores_combined)\n",
        "        c_index_combined = results_cindex_combined[0]\n",
        "\n",
        "        kmf1 = KaplanMeierFitter()\n",
        "        kmf2 = KaplanMeierFitter()\n",
        "\n",
        "        kmf1.fit(high_risk_time.astype('float') / 365, high_risk_event, label='High Risk')\n",
        "\n",
        "        kmf2.fit(low_risk_time.astype('float') / 365, low_risk_event, label='Low Risk')\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "\n",
        "        ax = kmf1.plot(color='r', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "        ax = kmf2.plot(color='g', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
        "        plt.title(\"COXR , \"+result_names[index_name], fontsize=font_label, fontweight='bold')\n",
        "        plt.xlabel(\"Time (Years)\", fontsize=font_label, fontweight='bold')\n",
        "        plt.ylabel(\"Survival probability\", fontsize=font_label, fontweight='bold')\n",
        "        plt.xticks(np.arange(int(years.min()), int(years.max()) + 1, 1.0))\n",
        "        plt.yticks(np.arange(0.0, 1.0, 0.1))\n",
        "        ax.grid(axis='both', which='both', color='lightgray', linestyle='-', linewidth=0.5,zorder=-1000)\n",
        "\n",
        "        # add_at_risk_counts(kmf1, kmf2 , ax=ax)\n",
        "        # plt.tight_layout()\n",
        "\n",
        "        fig.savefig(os.path.join('Plots', 'cph_{}-KaplanMier.jpg'.format(str(result_names[index_name]))), dpi=300)\n",
        "\n",
        "    #########################################################################################################\n",
        "\n",
        "    # Add Reported Results to its Data Frame\n",
        "    df_reported_results_cph.loc[len(df_reported_results_cph)] = [result_names[index_name], 'COXPH', mean_cindex_internal, std_cindex_internal,\n",
        "                                                                       mean_cindex_external, std_cindex_external, p_value_train, pvalue_external,\n",
        "                                                                       c_index_combined, pvalue_combined]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e67efdd3-a996-477b-83b1-a1147285785d",
      "metadata": {
        "id": "e67efdd3-a996-477b-83b1-a1147285785d"
      },
      "source": [
        "# Save All Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec134f68-615e-4252-9799-20b98b8c8db3",
      "metadata": {
        "id": "ec134f68-615e-4252-9799-20b98b8c8db3"
      },
      "outputs": [],
      "source": [
        "#concatenating all results along rows\n",
        "df_all_results = pd.concat([df_reported_results_rsf,df_reported_results_cwgbsa,df_reported_results_fssvm,df_reported_results_cph], axis=0, ignore_index=True)\n",
        "df_all_results.to_csv(os.path.join('Results', 'All Reported Results-2.csv'))\n",
        "df_all_results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
